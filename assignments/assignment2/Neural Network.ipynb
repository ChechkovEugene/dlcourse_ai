{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302029, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301685, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301851, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302623, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302031, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301124, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302831, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301638, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302170, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302117, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302455, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302807, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302832, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303278, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301772, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302333, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302433, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.301941, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302173, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x119a3aa90>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.275985, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.347515, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264348, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287890, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253264, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265011, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.212698, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.320777, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302624, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.311032, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234316, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.353994, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.217454, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.378711, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256101, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.309860, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264767, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276485, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274562, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.322051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308033, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317549, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262630, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270323, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308261, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264990, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278636, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267083, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279901, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276510, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314133, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256404, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295822, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278750, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280567, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255044, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240982, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315651, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.351801, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.319693, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.295926, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.345443, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.310013, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.326544, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.255641, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.199259, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.164561, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.025661, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.883798, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.263931, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.662918, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.245522, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.943906, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.663953, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.042200, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.418303, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.519709, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.823944, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.022291, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.585656, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.937038, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.908215, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.233499, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.095108, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.718242, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.162756, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.015933, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.363952, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.842670, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.657567, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.388463, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.911120, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.693765, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 2.010436, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.115900, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.613706, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.738574, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.885192, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 2.474042, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.119274, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.672047, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.767860, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.478802, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.926619, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.337383, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.683186, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.660081, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.401881, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.635264, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.635617, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.622938, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.854111, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.556636, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634732, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.076198, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.007559, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.531114, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.041336, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.022564, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.647379, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.369538, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.379903, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.986917, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.318972, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.283966, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.936269, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.196061, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.739352, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634901, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.201189, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.582981, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.742143, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.293135, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.748190, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.976545, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.357876, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.992895, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602046, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602167, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.173057, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.312798, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.564551, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.961713, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.274091, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.304703, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.958926, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.377168, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.657193, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.389767, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.576803, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.556738, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.175409, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.322616, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.251510, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.060407, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.661861, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.227308, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.597969, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.887250, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.338688, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.842966, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.160604, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.347215, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.223119, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.436648, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.535320, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.249121, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.248964, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.549803, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.259687, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.097239, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.324286, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.315431, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.420746, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.443017, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.301618, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.533658, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.607993, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.239065, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.649177, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.174445, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.602848, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.363682, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.160640, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.197888, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.126413, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.008120, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.643235, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.592807, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.412599, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.212850, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.196541, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.280346, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.403204, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.229377, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.400568, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.391042, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.102808, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.445285, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.406323, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.219193, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.449330, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.304464, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.494726, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.327706, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.361608, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.460816, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.424061, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.331042, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.319385, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.283704, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.309925, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.285989, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.352220, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.261306, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.287292, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.315104, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.268513, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.242892, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.047102, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.901234, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.948076, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.740618, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.914006, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.841368, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.927281, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.294955, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.815748, Train accuracy: 0.400000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.1, reg_strength=0.001, n_layers=100\n",
      "Loss: 1.931195, Train accuracy: 0.347111, val accuracy: 0.353000\n",
      "Loss: 2.011921, Train accuracy: 0.535333, val accuracy: 0.513000\n",
      "Loss: 1.675237, Train accuracy: 0.610222, val accuracy: 0.595000\n",
      "Loss: 1.924239, Train accuracy: 0.572667, val accuracy: 0.545000\n",
      "Loss: 1.610558, Train accuracy: 0.605889, val accuracy: 0.590000\n",
      "Loss: 1.752327, Train accuracy: 0.594667, val accuracy: 0.573000\n",
      "Loss: 1.988604, Train accuracy: 0.636778, val accuracy: 0.607000\n",
      "Loss: 1.629876, Train accuracy: 0.621667, val accuracy: 0.589000\n",
      "Loss: 1.812505, Train accuracy: 0.662667, val accuracy: 0.624000\n",
      "Loss: 1.602256, Train accuracy: 0.654556, val accuracy: 0.618000\n",
      "Loss: 1.856397, Train accuracy: 0.650222, val accuracy: 0.612000\n",
      "Loss: 1.211903, Train accuracy: 0.628778, val accuracy: 0.604000\n",
      "Loss: 2.354531, Train accuracy: 0.623778, val accuracy: 0.611000\n",
      "Loss: 2.237254, Train accuracy: 0.669667, val accuracy: 0.626000\n",
      "Loss: 1.500078, Train accuracy: 0.654333, val accuracy: 0.627000\n",
      "Loss: 1.202888, Train accuracy: 0.654444, val accuracy: 0.639000\n",
      "Loss: 1.638726, Train accuracy: 0.651444, val accuracy: 0.640000\n",
      "Loss: 1.650322, Train accuracy: 0.615444, val accuracy: 0.585000\n",
      "Loss: 1.244468, Train accuracy: 0.676667, val accuracy: 0.641000\n",
      "Loss: 1.380760, Train accuracy: 0.645667, val accuracy: 0.615000\n",
      "learning_rate=0.1, reg_strength=0.001, n_layers=200\n",
      "Loss: 1.741136, Train accuracy: 0.358778, val accuracy: 0.380000\n",
      "Loss: 2.002868, Train accuracy: 0.535667, val accuracy: 0.532000\n",
      "Loss: 1.988324, Train accuracy: 0.570444, val accuracy: 0.556000\n",
      "Loss: 1.796841, Train accuracy: 0.596667, val accuracy: 0.565000\n",
      "Loss: 1.896630, Train accuracy: 0.568444, val accuracy: 0.535000\n",
      "Loss: 0.994295, Train accuracy: 0.599444, val accuracy: 0.596000\n",
      "Loss: 1.392420, Train accuracy: 0.613667, val accuracy: 0.577000\n",
      "Loss: 1.549245, Train accuracy: 0.627222, val accuracy: 0.591000\n",
      "Loss: 2.219200, Train accuracy: 0.622889, val accuracy: 0.588000\n",
      "Loss: 2.565500, Train accuracy: 0.658778, val accuracy: 0.641000\n",
      "Loss: 1.640281, Train accuracy: 0.626667, val accuracy: 0.591000\n",
      "Loss: 2.234996, Train accuracy: 0.632889, val accuracy: 0.622000\n",
      "Loss: 1.457940, Train accuracy: 0.662444, val accuracy: 0.634000\n",
      "Loss: 1.747556, Train accuracy: 0.659556, val accuracy: 0.617000\n",
      "Loss: 1.941204, Train accuracy: 0.631556, val accuracy: 0.597000\n",
      "Loss: 1.346704, Train accuracy: 0.708556, val accuracy: 0.682000\n",
      "Loss: 1.862989, Train accuracy: 0.612778, val accuracy: 0.578000\n",
      "Loss: 1.521394, Train accuracy: 0.621556, val accuracy: 0.594000\n",
      "Loss: 1.626668, Train accuracy: 0.685333, val accuracy: 0.659000\n",
      "Loss: 1.536735, Train accuracy: 0.627333, val accuracy: 0.606000\n",
      "learning_rate=0.1, reg_strength=0.001, n_layers=500\n",
      "Loss: 1.889677, Train accuracy: 0.395444, val accuracy: 0.402000\n",
      "Loss: 1.396668, Train accuracy: 0.523222, val accuracy: 0.524000\n",
      "Loss: 1.717474, Train accuracy: 0.572556, val accuracy: 0.557000\n",
      "Loss: 1.474152, Train accuracy: 0.600889, val accuracy: 0.592000\n",
      "Loss: 1.766798, Train accuracy: 0.552556, val accuracy: 0.523000\n",
      "Loss: 2.230935, Train accuracy: 0.586556, val accuracy: 0.565000\n",
      "Loss: 1.613827, Train accuracy: 0.685778, val accuracy: 0.663000\n",
      "Loss: 1.494120, Train accuracy: 0.574667, val accuracy: 0.559000\n",
      "Loss: 1.964103, Train accuracy: 0.637444, val accuracy: 0.593000\n",
      "Loss: 1.828276, Train accuracy: 0.653444, val accuracy: 0.607000\n",
      "Loss: 1.977116, Train accuracy: 0.635333, val accuracy: 0.582000\n",
      "Loss: 1.807910, Train accuracy: 0.600444, val accuracy: 0.553000\n",
      "Loss: 1.774529, Train accuracy: 0.642889, val accuracy: 0.599000\n",
      "Loss: 1.935263, Train accuracy: 0.650222, val accuracy: 0.621000\n",
      "Loss: 1.892348, Train accuracy: 0.668556, val accuracy: 0.620000\n",
      "Loss: 1.605624, Train accuracy: 0.684111, val accuracy: 0.634000\n",
      "Loss: 1.847437, Train accuracy: 0.686889, val accuracy: 0.655000\n",
      "Loss: 1.680912, Train accuracy: 0.685000, val accuracy: 0.630000\n",
      "Loss: 2.393220, Train accuracy: 0.663889, val accuracy: 0.627000\n",
      "Loss: 1.660922, Train accuracy: 0.639111, val accuracy: 0.603000\n",
      "learning_rate=0.1, reg_strength=0.0001, n_layers=100\n",
      "Loss: 1.648534, Train accuracy: 0.376444, val accuracy: 0.382000\n",
      "Loss: 1.462312, Train accuracy: 0.543333, val accuracy: 0.538000\n",
      "Loss: 1.667419, Train accuracy: 0.595889, val accuracy: 0.567000\n",
      "Loss: 1.514939, Train accuracy: 0.624111, val accuracy: 0.588000\n",
      "Loss: 1.362082, Train accuracy: 0.673556, val accuracy: 0.653000\n",
      "Loss: 1.485331, Train accuracy: 0.679556, val accuracy: 0.639000\n",
      "Loss: 1.170469, Train accuracy: 0.667000, val accuracy: 0.607000\n",
      "Loss: 0.935762, Train accuracy: 0.652000, val accuracy: 0.600000\n",
      "Loss: 0.962305, Train accuracy: 0.702444, val accuracy: 0.638000\n",
      "Loss: 1.328205, Train accuracy: 0.700667, val accuracy: 0.652000\n",
      "Loss: 1.258510, Train accuracy: 0.683444, val accuracy: 0.631000\n",
      "Loss: 0.788887, Train accuracy: 0.736778, val accuracy: 0.663000\n",
      "Loss: 0.998052, Train accuracy: 0.761222, val accuracy: 0.680000\n",
      "Loss: 0.979795, Train accuracy: 0.740778, val accuracy: 0.668000\n",
      "Loss: 0.589003, Train accuracy: 0.769556, val accuracy: 0.677000\n",
      "Loss: 0.789512, Train accuracy: 0.775889, val accuracy: 0.687000\n",
      "Loss: 1.379345, Train accuracy: 0.743778, val accuracy: 0.634000\n",
      "Loss: 0.907893, Train accuracy: 0.737778, val accuracy: 0.632000\n",
      "Loss: 1.003232, Train accuracy: 0.777667, val accuracy: 0.693000\n",
      "Loss: 1.172113, Train accuracy: 0.751222, val accuracy: 0.651000\n",
      "learning_rate=0.1, reg_strength=0.0001, n_layers=200\n",
      "Loss: 2.068661, Train accuracy: 0.388778, val accuracy: 0.401000\n",
      "Loss: 1.457918, Train accuracy: 0.568778, val accuracy: 0.543000\n",
      "Loss: 1.219922, Train accuracy: 0.593111, val accuracy: 0.563000\n",
      "Loss: 0.871734, Train accuracy: 0.610889, val accuracy: 0.591000\n",
      "Loss: 1.334514, Train accuracy: 0.653333, val accuracy: 0.589000\n",
      "Loss: 1.078829, Train accuracy: 0.681889, val accuracy: 0.664000\n",
      "Loss: 1.908028, Train accuracy: 0.652444, val accuracy: 0.625000\n",
      "Loss: 1.159535, Train accuracy: 0.725333, val accuracy: 0.671000\n",
      "Loss: 1.022069, Train accuracy: 0.685556, val accuracy: 0.646000\n",
      "Loss: 1.012014, Train accuracy: 0.739222, val accuracy: 0.675000\n",
      "Loss: 0.948284, Train accuracy: 0.728667, val accuracy: 0.641000\n",
      "Loss: 1.006020, Train accuracy: 0.746556, val accuracy: 0.683000\n",
      "Loss: 1.227508, Train accuracy: 0.771000, val accuracy: 0.702000\n",
      "Loss: 1.066458, Train accuracy: 0.734000, val accuracy: 0.653000\n",
      "Loss: 0.927110, Train accuracy: 0.744778, val accuracy: 0.657000\n",
      "Loss: 0.829786, Train accuracy: 0.736667, val accuracy: 0.646000\n",
      "Loss: 1.147736, Train accuracy: 0.770778, val accuracy: 0.685000\n",
      "Loss: 1.192963, Train accuracy: 0.761111, val accuracy: 0.673000\n",
      "Loss: 1.398228, Train accuracy: 0.763222, val accuracy: 0.685000\n",
      "Loss: 1.627474, Train accuracy: 0.735111, val accuracy: 0.638000\n",
      "learning_rate=0.1, reg_strength=0.0001, n_layers=500\n",
      "Loss: 1.616855, Train accuracy: 0.394111, val accuracy: 0.401000\n",
      "Loss: 1.824762, Train accuracy: 0.560667, val accuracy: 0.538000\n",
      "Loss: 1.871195, Train accuracy: 0.617000, val accuracy: 0.598000\n",
      "Loss: 1.791827, Train accuracy: 0.633222, val accuracy: 0.587000\n",
      "Loss: 0.970828, Train accuracy: 0.648667, val accuracy: 0.614000\n",
      "Loss: 0.809231, Train accuracy: 0.676667, val accuracy: 0.622000\n",
      "Loss: 1.505168, Train accuracy: 0.698667, val accuracy: 0.656000\n",
      "Loss: 1.575462, Train accuracy: 0.720889, val accuracy: 0.643000\n",
      "Loss: 1.690227, Train accuracy: 0.697556, val accuracy: 0.635000\n",
      "Loss: 2.485887, Train accuracy: 0.678111, val accuracy: 0.628000\n",
      "Loss: 1.602382, Train accuracy: 0.703889, val accuracy: 0.637000\n",
      "Loss: 1.844317, Train accuracy: 0.776778, val accuracy: 0.686000\n",
      "Loss: 1.232254, Train accuracy: 0.742667, val accuracy: 0.663000\n",
      "Loss: 2.211509, Train accuracy: 0.721556, val accuracy: 0.649000\n",
      "Loss: 1.311680, Train accuracy: 0.754667, val accuracy: 0.669000\n",
      "Loss: 1.967468, Train accuracy: 0.756778, val accuracy: 0.672000\n",
      "Loss: 1.564105, Train accuracy: 0.781333, val accuracy: 0.680000\n",
      "Loss: 1.450595, Train accuracy: 0.720000, val accuracy: 0.634000\n",
      "Loss: 1.644991, Train accuracy: 0.771889, val accuracy: 0.678000\n",
      "Loss: 1.097207, Train accuracy: 0.749000, val accuracy: 0.668000\n",
      "learning_rate=0.1, reg_strength=1e-05, n_layers=100\n",
      "Loss: 2.117981, Train accuracy: 0.340667, val accuracy: 0.332000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.745534, Train accuracy: 0.526444, val accuracy: 0.519000\n",
      "Loss: 0.922529, Train accuracy: 0.579333, val accuracy: 0.556000\n",
      "Loss: 1.379466, Train accuracy: 0.628889, val accuracy: 0.604000\n",
      "Loss: 1.069691, Train accuracy: 0.670333, val accuracy: 0.624000\n",
      "Loss: 1.559632, Train accuracy: 0.674444, val accuracy: 0.600000\n",
      "Loss: 0.982200, Train accuracy: 0.696333, val accuracy: 0.640000\n",
      "Loss: 1.537308, Train accuracy: 0.716778, val accuracy: 0.663000\n",
      "Loss: 1.263424, Train accuracy: 0.694000, val accuracy: 0.647000\n",
      "Loss: 1.411178, Train accuracy: 0.701222, val accuracy: 0.634000\n",
      "Loss: 1.103295, Train accuracy: 0.728556, val accuracy: 0.653000\n",
      "Loss: 1.017744, Train accuracy: 0.738667, val accuracy: 0.652000\n",
      "Loss: 0.672471, Train accuracy: 0.741556, val accuracy: 0.667000\n",
      "Loss: 1.198415, Train accuracy: 0.712444, val accuracy: 0.635000\n",
      "Loss: 1.126366, Train accuracy: 0.768111, val accuracy: 0.687000\n",
      "Loss: 0.803654, Train accuracy: 0.781000, val accuracy: 0.690000\n",
      "Loss: 1.012459, Train accuracy: 0.762556, val accuracy: 0.653000\n",
      "Loss: 0.691911, Train accuracy: 0.777556, val accuracy: 0.674000\n",
      "Loss: 1.011749, Train accuracy: 0.760111, val accuracy: 0.661000\n",
      "Loss: 1.443839, Train accuracy: 0.778000, val accuracy: 0.667000\n",
      "learning_rate=0.1, reg_strength=1e-05, n_layers=200\n",
      "Loss: 1.776210, Train accuracy: 0.402667, val accuracy: 0.409000\n",
      "Loss: 1.558728, Train accuracy: 0.537667, val accuracy: 0.533000\n",
      "Loss: 1.024831, Train accuracy: 0.551667, val accuracy: 0.523000\n",
      "Loss: 0.806019, Train accuracy: 0.622889, val accuracy: 0.594000\n",
      "Loss: 1.032245, Train accuracy: 0.657333, val accuracy: 0.623000\n",
      "Loss: 0.833828, Train accuracy: 0.655000, val accuracy: 0.605000\n",
      "Loss: 1.425961, Train accuracy: 0.707556, val accuracy: 0.643000\n",
      "Loss: 1.163853, Train accuracy: 0.693111, val accuracy: 0.632000\n",
      "Loss: 0.800265, Train accuracy: 0.735222, val accuracy: 0.667000\n",
      "Loss: 1.255853, Train accuracy: 0.732556, val accuracy: 0.659000\n",
      "Loss: 1.380636, Train accuracy: 0.749333, val accuracy: 0.694000\n",
      "Loss: 0.775011, Train accuracy: 0.760333, val accuracy: 0.671000\n",
      "Loss: 0.768091, Train accuracy: 0.729000, val accuracy: 0.649000\n",
      "Loss: 1.543539, Train accuracy: 0.755000, val accuracy: 0.655000\n",
      "Loss: 1.107653, Train accuracy: 0.750333, val accuracy: 0.632000\n",
      "Loss: 1.469520, Train accuracy: 0.712778, val accuracy: 0.636000\n",
      "Loss: 0.899930, Train accuracy: 0.744778, val accuracy: 0.668000\n",
      "Loss: 0.681142, Train accuracy: 0.795000, val accuracy: 0.689000\n",
      "Loss: 0.879815, Train accuracy: 0.760667, val accuracy: 0.651000\n",
      "Loss: 0.717666, Train accuracy: 0.796000, val accuracy: 0.675000\n",
      "learning_rate=0.1, reg_strength=1e-05, n_layers=500\n",
      "Loss: 1.641100, Train accuracy: 0.406111, val accuracy: 0.405000\n",
      "Loss: 1.508845, Train accuracy: 0.553889, val accuracy: 0.559000\n",
      "Loss: 1.298547, Train accuracy: 0.579889, val accuracy: 0.556000\n",
      "Loss: 2.292091, Train accuracy: 0.632556, val accuracy: 0.608000\n",
      "Loss: 1.262253, Train accuracy: 0.634667, val accuracy: 0.586000\n",
      "Loss: 0.769795, Train accuracy: 0.684333, val accuracy: 0.612000\n",
      "Loss: 1.206656, Train accuracy: 0.690333, val accuracy: 0.631000\n",
      "Loss: 1.546033, Train accuracy: 0.705333, val accuracy: 0.639000\n",
      "Loss: 0.925255, Train accuracy: 0.724333, val accuracy: 0.662000\n",
      "Loss: 1.336004, Train accuracy: 0.672667, val accuracy: 0.587000\n",
      "Loss: 1.525015, Train accuracy: 0.702444, val accuracy: 0.635000\n",
      "Loss: 2.175993, Train accuracy: 0.712556, val accuracy: 0.641000\n",
      "Loss: 1.683623, Train accuracy: 0.676333, val accuracy: 0.588000\n",
      "Loss: 2.074184, Train accuracy: 0.778889, val accuracy: 0.678000\n",
      "Loss: 0.600167, Train accuracy: 0.779778, val accuracy: 0.672000\n",
      "Loss: 0.770690, Train accuracy: 0.776667, val accuracy: 0.659000\n",
      "Loss: 1.372920, Train accuracy: 0.738667, val accuracy: 0.649000\n",
      "Loss: 0.599955, Train accuracy: 0.757778, val accuracy: 0.641000\n",
      "Loss: 0.828349, Train accuracy: 0.780889, val accuracy: 0.663000\n",
      "Loss: 1.253194, Train accuracy: 0.742556, val accuracy: 0.643000\n",
      "learning_rate=0.01, reg_strength=0.001, n_layers=100\n",
      "Loss: 2.238496, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.310484, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.224937, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.035381, Train accuracy: 0.251444, val accuracy: 0.254000\n",
      "Loss: 1.887861, Train accuracy: 0.309444, val accuracy: 0.315000\n",
      "Loss: 1.745022, Train accuracy: 0.378222, val accuracy: 0.381000\n",
      "Loss: 1.554710, Train accuracy: 0.463889, val accuracy: 0.467000\n",
      "Loss: 1.355380, Train accuracy: 0.527222, val accuracy: 0.526000\n",
      "Loss: 1.431985, Train accuracy: 0.570222, val accuracy: 0.559000\n",
      "Loss: 1.313193, Train accuracy: 0.612222, val accuracy: 0.593000\n",
      "Loss: 1.230673, Train accuracy: 0.633222, val accuracy: 0.630000\n",
      "Loss: 1.470339, Train accuracy: 0.656222, val accuracy: 0.643000\n",
      "Loss: 1.262442, Train accuracy: 0.680111, val accuracy: 0.664000\n",
      "Loss: 1.320879, Train accuracy: 0.703222, val accuracy: 0.688000\n",
      "Loss: 0.990403, Train accuracy: 0.711222, val accuracy: 0.699000\n",
      "Loss: 1.164603, Train accuracy: 0.713556, val accuracy: 0.687000\n",
      "Loss: 1.457031, Train accuracy: 0.715778, val accuracy: 0.699000\n",
      "Loss: 1.122396, Train accuracy: 0.741667, val accuracy: 0.703000\n",
      "Loss: 1.068041, Train accuracy: 0.744444, val accuracy: 0.700000\n",
      "Loss: 1.070474, Train accuracy: 0.748667, val accuracy: 0.708000\n",
      "learning_rate=0.01, reg_strength=0.001, n_layers=200\n",
      "Loss: 2.306646, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.179572, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.248885, Train accuracy: 0.207000, val accuracy: 0.213000\n",
      "Loss: 1.985980, Train accuracy: 0.265000, val accuracy: 0.262000\n",
      "Loss: 1.850556, Train accuracy: 0.323000, val accuracy: 0.329000\n",
      "Loss: 1.856853, Train accuracy: 0.410222, val accuracy: 0.399000\n",
      "Loss: 1.517605, Train accuracy: 0.482444, val accuracy: 0.481000\n",
      "Loss: 1.413813, Train accuracy: 0.560000, val accuracy: 0.548000\n",
      "Loss: 1.417780, Train accuracy: 0.593778, val accuracy: 0.572000\n",
      "Loss: 1.442946, Train accuracy: 0.623556, val accuracy: 0.610000\n",
      "Loss: 1.243257, Train accuracy: 0.654667, val accuracy: 0.629000\n",
      "Loss: 1.290858, Train accuracy: 0.675778, val accuracy: 0.635000\n",
      "Loss: 1.094087, Train accuracy: 0.697667, val accuracy: 0.674000\n",
      "Loss: 1.359742, Train accuracy: 0.714333, val accuracy: 0.697000\n",
      "Loss: 0.892931, Train accuracy: 0.711778, val accuracy: 0.693000\n",
      "Loss: 1.035202, Train accuracy: 0.729111, val accuracy: 0.675000\n",
      "Loss: 0.988816, Train accuracy: 0.747667, val accuracy: 0.699000\n",
      "Loss: 1.097984, Train accuracy: 0.746444, val accuracy: 0.712000\n",
      "Loss: 1.128275, Train accuracy: 0.761444, val accuracy: 0.728000\n",
      "Loss: 1.274140, Train accuracy: 0.770667, val accuracy: 0.720000\n",
      "learning_rate=0.01, reg_strength=0.001, n_layers=500\n",
      "Loss: 2.223777, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297498, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.929590, Train accuracy: 0.217333, val accuracy: 0.227000\n",
      "Loss: 2.099890, Train accuracy: 0.288444, val accuracy: 0.295000\n",
      "Loss: 1.618362, Train accuracy: 0.387000, val accuracy: 0.382000\n",
      "Loss: 1.291961, Train accuracy: 0.460333, val accuracy: 0.448000\n",
      "Loss: 1.333509, Train accuracy: 0.532111, val accuracy: 0.543000\n",
      "Loss: 1.258233, Train accuracy: 0.587889, val accuracy: 0.571000\n",
      "Loss: 1.458786, Train accuracy: 0.614889, val accuracy: 0.601000\n",
      "Loss: 1.132979, Train accuracy: 0.653222, val accuracy: 0.644000\n",
      "Loss: 1.278055, Train accuracy: 0.679444, val accuracy: 0.662000\n",
      "Loss: 0.975440, Train accuracy: 0.692111, val accuracy: 0.684000\n",
      "Loss: 1.275209, Train accuracy: 0.707556, val accuracy: 0.705000\n",
      "Loss: 1.272943, Train accuracy: 0.715667, val accuracy: 0.698000\n",
      "Loss: 1.079762, Train accuracy: 0.727667, val accuracy: 0.702000\n",
      "Loss: 1.182593, Train accuracy: 0.738556, val accuracy: 0.717000\n",
      "Loss: 0.743215, Train accuracy: 0.761444, val accuracy: 0.721000\n",
      "Loss: 1.064328, Train accuracy: 0.761222, val accuracy: 0.712000\n",
      "Loss: 0.926641, Train accuracy: 0.771222, val accuracy: 0.727000\n",
      "Loss: 1.077212, Train accuracy: 0.777222, val accuracy: 0.726000\n",
      "learning_rate=0.01, reg_strength=0.0001, n_layers=100\n",
      "Loss: 2.228590, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.244945, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.154968, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.158071, Train accuracy: 0.262444, val accuracy: 0.268000\n",
      "Loss: 1.983382, Train accuracy: 0.318667, val accuracy: 0.326000\n",
      "Loss: 1.803622, Train accuracy: 0.426000, val accuracy: 0.421000\n",
      "Loss: 1.484775, Train accuracy: 0.487778, val accuracy: 0.480000\n",
      "Loss: 1.369720, Train accuracy: 0.551000, val accuracy: 0.544000\n",
      "Loss: 1.034517, Train accuracy: 0.597667, val accuracy: 0.597000\n",
      "Loss: 1.434873, Train accuracy: 0.633889, val accuracy: 0.618000\n",
      "Loss: 1.514417, Train accuracy: 0.645889, val accuracy: 0.643000\n",
      "Loss: 1.225701, Train accuracy: 0.683111, val accuracy: 0.670000\n",
      "Loss: 0.814110, Train accuracy: 0.693889, val accuracy: 0.673000\n",
      "Loss: 0.694601, Train accuracy: 0.710111, val accuracy: 0.689000\n",
      "Loss: 0.984627, Train accuracy: 0.718556, val accuracy: 0.685000\n",
      "Loss: 0.837269, Train accuracy: 0.731444, val accuracy: 0.683000\n",
      "Loss: 0.886815, Train accuracy: 0.743111, val accuracy: 0.706000\n",
      "Loss: 0.734502, Train accuracy: 0.749000, val accuracy: 0.707000\n",
      "Loss: 1.123854, Train accuracy: 0.741333, val accuracy: 0.694000\n",
      "Loss: 0.727915, Train accuracy: 0.758222, val accuracy: 0.692000\n",
      "learning_rate=0.01, reg_strength=0.0001, n_layers=200\n",
      "Loss: 2.168482, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285501, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.178706, Train accuracy: 0.199889, val accuracy: 0.208000\n",
      "Loss: 2.032371, Train accuracy: 0.270667, val accuracy: 0.270000\n",
      "Loss: 2.025241, Train accuracy: 0.323556, val accuracy: 0.322000\n",
      "Loss: 1.714934, Train accuracy: 0.405556, val accuracy: 0.402000\n",
      "Loss: 1.554311, Train accuracy: 0.488889, val accuracy: 0.492000\n",
      "Loss: 1.598176, Train accuracy: 0.549667, val accuracy: 0.534000\n",
      "Loss: 1.348573, Train accuracy: 0.614111, val accuracy: 0.590000\n",
      "Loss: 0.968667, Train accuracy: 0.640889, val accuracy: 0.616000\n",
      "Loss: 1.019425, Train accuracy: 0.672889, val accuracy: 0.661000\n",
      "Loss: 1.068258, Train accuracy: 0.687667, val accuracy: 0.672000\n",
      "Loss: 0.866057, Train accuracy: 0.707444, val accuracy: 0.680000\n",
      "Loss: 0.900666, Train accuracy: 0.723556, val accuracy: 0.694000\n",
      "Loss: 0.579671, Train accuracy: 0.734000, val accuracy: 0.698000\n",
      "Loss: 0.829264, Train accuracy: 0.743778, val accuracy: 0.694000\n",
      "Loss: 0.738429, Train accuracy: 0.744556, val accuracy: 0.706000\n",
      "Loss: 1.138288, Train accuracy: 0.756556, val accuracy: 0.698000\n",
      "Loss: 0.833700, Train accuracy: 0.776222, val accuracy: 0.715000\n",
      "Loss: 0.738292, Train accuracy: 0.780556, val accuracy: 0.716000\n",
      "learning_rate=0.01, reg_strength=0.0001, n_layers=500\n",
      "Loss: 2.267154, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256361, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.162315, Train accuracy: 0.230222, val accuracy: 0.234000\n",
      "Loss: 2.107636, Train accuracy: 0.299889, val accuracy: 0.307000\n",
      "Loss: 1.578885, Train accuracy: 0.389111, val accuracy: 0.387000\n",
      "Loss: 1.531421, Train accuracy: 0.487889, val accuracy: 0.487000\n",
      "Loss: 1.270610, Train accuracy: 0.540333, val accuracy: 0.530000\n",
      "Loss: 1.441439, Train accuracy: 0.607778, val accuracy: 0.591000\n",
      "Loss: 1.344971, Train accuracy: 0.631333, val accuracy: 0.614000\n",
      "Loss: 1.264269, Train accuracy: 0.664333, val accuracy: 0.643000\n",
      "Loss: 0.960050, Train accuracy: 0.690667, val accuracy: 0.674000\n",
      "Loss: 1.274774, Train accuracy: 0.700778, val accuracy: 0.682000\n",
      "Loss: 0.910104, Train accuracy: 0.716778, val accuracy: 0.688000\n",
      "Loss: 0.900358, Train accuracy: 0.736333, val accuracy: 0.716000\n",
      "Loss: 1.125678, Train accuracy: 0.751000, val accuracy: 0.715000\n",
      "Loss: 0.958231, Train accuracy: 0.754111, val accuracy: 0.701000\n",
      "Loss: 0.660487, Train accuracy: 0.768778, val accuracy: 0.730000\n",
      "Loss: 0.788019, Train accuracy: 0.778222, val accuracy: 0.733000\n",
      "Loss: 0.676732, Train accuracy: 0.783667, val accuracy: 0.731000\n",
      "Loss: 0.807528, Train accuracy: 0.785778, val accuracy: 0.728000\n",
      "learning_rate=0.01, reg_strength=1e-05, n_layers=100\n",
      "Loss: 2.188594, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.218913, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.101292, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.215187, Train accuracy: 0.256556, val accuracy: 0.253000\n",
      "Loss: 2.014694, Train accuracy: 0.317000, val accuracy: 0.320000\n",
      "Loss: 1.599899, Train accuracy: 0.386444, val accuracy: 0.380000\n",
      "Loss: 1.580555, Train accuracy: 0.454000, val accuracy: 0.462000\n",
      "Loss: 1.453046, Train accuracy: 0.546556, val accuracy: 0.540000\n",
      "Loss: 1.359257, Train accuracy: 0.598222, val accuracy: 0.603000\n",
      "Loss: 1.030620, Train accuracy: 0.637333, val accuracy: 0.617000\n",
      "Loss: 1.050493, Train accuracy: 0.648111, val accuracy: 0.641000\n",
      "Loss: 1.314662, Train accuracy: 0.681889, val accuracy: 0.666000\n",
      "Loss: 1.110195, Train accuracy: 0.697889, val accuracy: 0.687000\n",
      "Loss: 0.782771, Train accuracy: 0.705889, val accuracy: 0.680000\n",
      "Loss: 0.794569, Train accuracy: 0.694889, val accuracy: 0.671000\n",
      "Loss: 1.189274, Train accuracy: 0.736778, val accuracy: 0.693000\n",
      "Loss: 0.807318, Train accuracy: 0.741667, val accuracy: 0.694000\n",
      "Loss: 0.612828, Train accuracy: 0.749333, val accuracy: 0.699000\n",
      "Loss: 0.623808, Train accuracy: 0.751778, val accuracy: 0.699000\n",
      "Loss: 0.924173, Train accuracy: 0.780889, val accuracy: 0.719000\n",
      "learning_rate=0.01, reg_strength=1e-05, n_layers=200\n",
      "Loss: 2.201813, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.172369, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.165464, Train accuracy: 0.205222, val accuracy: 0.215000\n",
      "Loss: 1.932398, Train accuracy: 0.276444, val accuracy: 0.276000\n",
      "Loss: 1.896248, Train accuracy: 0.363444, val accuracy: 0.356000\n",
      "Loss: 1.377530, Train accuracy: 0.451889, val accuracy: 0.456000\n",
      "Loss: 1.700218, Train accuracy: 0.526556, val accuracy: 0.529000\n",
      "Loss: 1.322789, Train accuracy: 0.571111, val accuracy: 0.566000\n",
      "Loss: 1.398131, Train accuracy: 0.609444, val accuracy: 0.604000\n",
      "Loss: 1.187533, Train accuracy: 0.653000, val accuracy: 0.632000\n",
      "Loss: 1.229939, Train accuracy: 0.673889, val accuracy: 0.655000\n",
      "Loss: 1.012852, Train accuracy: 0.688889, val accuracy: 0.685000\n",
      "Loss: 1.074326, Train accuracy: 0.706444, val accuracy: 0.672000\n",
      "Loss: 1.277843, Train accuracy: 0.716889, val accuracy: 0.679000\n",
      "Loss: 1.108524, Train accuracy: 0.734444, val accuracy: 0.709000\n",
      "Loss: 0.948963, Train accuracy: 0.744111, val accuracy: 0.705000\n",
      "Loss: 0.746428, Train accuracy: 0.760222, val accuracy: 0.727000\n",
      "Loss: 0.982102, Train accuracy: 0.764333, val accuracy: 0.730000\n",
      "Loss: 0.731407, Train accuracy: 0.775111, val accuracy: 0.726000\n",
      "Loss: 0.784688, Train accuracy: 0.775333, val accuracy: 0.724000\n",
      "learning_rate=0.01, reg_strength=1e-05, n_layers=500\n",
      "Loss: 2.187794, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228276, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.005662, Train accuracy: 0.220889, val accuracy: 0.222000\n",
      "Loss: 2.047543, Train accuracy: 0.290889, val accuracy: 0.297000\n",
      "Loss: 1.769890, Train accuracy: 0.402333, val accuracy: 0.388000\n",
      "Loss: 1.796453, Train accuracy: 0.497444, val accuracy: 0.483000\n",
      "Loss: 1.686541, Train accuracy: 0.546667, val accuracy: 0.552000\n",
      "Loss: 1.240586, Train accuracy: 0.598000, val accuracy: 0.586000\n",
      "Loss: 1.265677, Train accuracy: 0.644222, val accuracy: 0.631000\n",
      "Loss: 1.018802, Train accuracy: 0.661556, val accuracy: 0.651000\n",
      "Loss: 0.922343, Train accuracy: 0.692889, val accuracy: 0.664000\n",
      "Loss: 0.916125, Train accuracy: 0.689556, val accuracy: 0.683000\n",
      "Loss: 0.899040, Train accuracy: 0.720000, val accuracy: 0.693000\n",
      "Loss: 0.682359, Train accuracy: 0.737333, val accuracy: 0.710000\n",
      "Loss: 1.011719, Train accuracy: 0.747444, val accuracy: 0.702000\n",
      "Loss: 0.990008, Train accuracy: 0.767556, val accuracy: 0.725000\n",
      "Loss: 0.701434, Train accuracy: 0.771889, val accuracy: 0.721000\n",
      "Loss: 0.633387, Train accuracy: 0.779667, val accuracy: 0.729000\n",
      "Loss: 0.739868, Train accuracy: 0.791333, val accuracy: 0.731000\n",
      "Loss: 0.692836, Train accuracy: 0.791444, val accuracy: 0.725000\n",
      "learning_rate=0.001, reg_strength=0.001, n_layers=100\n",
      "Loss: 2.282715, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265993, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234463, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288546, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291221, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.268332, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304493, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.173886, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.221673, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.145866, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.198574, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.144972, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.145405, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.122769, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271821, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266814, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.164263, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.174548, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.060147, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228498, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "learning_rate=0.001, reg_strength=0.001, n_layers=200\n",
      "Loss: 2.289521, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282168, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.229253, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259227, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.221569, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289347, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291077, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256505, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242726, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.224763, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263053, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.199149, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.204674, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.232723, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272076, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.214882, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250984, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238365, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.316692, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254314, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "learning_rate=0.001, reg_strength=0.001, n_layers=500\n",
      "Loss: 2.278023, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271301, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283617, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213674, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.181275, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.191274, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294475, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.183618, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259695, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.101488, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288319, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.203916, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279199, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.216114, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.307165, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299657, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.169621, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.186375, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209269, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.046961, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "learning_rate=0.001, reg_strength=0.0001, n_layers=100\n",
      "Loss: 2.285238, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277095, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275191, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230163, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268531, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262335, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315838, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.189806, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.160065, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258211, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295275, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.125034, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234609, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.208449, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230303, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.310286, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223991, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.220444, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.336736, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223648, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "learning_rate=0.001, reg_strength=0.0001, n_layers=200\n",
      "Loss: 2.284240, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264207, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291709, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260084, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295931, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.153034, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.219778, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.150809, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.235161, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.204820, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.162333, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.246640, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.143087, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.191538, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257691, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.221732, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260965, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.218974, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.129649, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.193696, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "learning_rate=0.001, reg_strength=0.0001, n_layers=500\n",
      "Loss: 2.277444, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287430, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240412, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.160131, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233175, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.195389, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.249852, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.125935, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301972, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250673, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.122076, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.337483, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.115856, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.170238, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.212360, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.148357, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254068, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243707, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.170209, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.125291, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "learning_rate=0.001, reg_strength=1e-05, n_layers=100\n",
      "Loss: 2.277974, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259042, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251279, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314019, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.252184, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247874, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209511, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.255073, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.148074, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.215185, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317184, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.208929, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254621, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.325615, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.183290, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.224039, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.161829, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.132176, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.202632, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.184816, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "learning_rate=0.001, reg_strength=1e-05, n_layers=200\n",
      "Loss: 2.302945, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277588, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250490, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213766, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228716, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.219034, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.204603, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.190472, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.221080, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267939, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225957, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.166001, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.224972, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.232163, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295821, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285437, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286304, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255658, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243679, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.203631, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "learning_rate=0.001, reg_strength=1e-05, n_layers=500\n",
      "Loss: 2.295399, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274914, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225582, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278813, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.193529, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283643, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.144421, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.169759, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.188584, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294398, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.172127, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.241859, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.186487, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254979, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242777, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.207451, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262857, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.138772, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.133481, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.128872, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "best validation accuracy achieved: 0.728000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-4\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "num_epochs = 20\n",
    "learning_rates = [1e-1, 1e-2, 1e-3]\n",
    "reg_strength = [1e-3, 1e-4, 1e-5]\n",
    "hidden_layer_size = [100, 200, 500]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for rs in reg_strength:\n",
    "        for hls in hidden_layer_size:\n",
    "            print(f'learning_rate={lr}, reg_strength={rs}, n_layers={hls}')\n",
    "    \n",
    "            model = TwoLayerNet(n_input=train_X.shape[1], n_output=10, hidden_layer_size=hls, reg=rs)\n",
    "            dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "            trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=lr, num_epochs=num_epochs, batch_size=batch_size)\n",
    "            loss_hist, train_hist, val_hist = trainer.fit()\n",
    "            accuracy = val_hist[-1]\n",
    "            \n",
    "            if not best_val_accuracy or accuracy > best_val_accuracy:\n",
    "                best_classifier = model\n",
    "                best_val_accuracy = accuracy\n",
    "                loss_history = loss_hist\n",
    "                train_history = train_hist\n",
    "                val_history = val_hist\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x119e02f50>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.669000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
